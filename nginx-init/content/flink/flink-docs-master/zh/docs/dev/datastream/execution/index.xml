<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>管理执行 on Apache Flink</title>
    <link>//localhost/flink/flink-docs-master/zh/docs/dev/datastream/execution/</link>
    <description>Recent content in 管理执行 on Apache Flink</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="//localhost/flink/flink-docs-master/zh/docs/dev/datastream/execution/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>执行配置</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/datastream/execution/execution_configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/datastream/execution/execution_configuration/</guid>
      <description>执行配置 # StreamExecutionEnvironment 包含了 ExecutionConfig，它允许在运行时设置作业特定的配置值。要更改影响所有作业的默认值，请参阅配置。
Java StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); ExecutionConfig executionConfig = env.getConfig(); Scala val env = StreamExecutionEnvironment.getExecutionEnvironment var executionConfig = env.getConfig Python env = StreamExecutionEnvironment.get_execution_environment() execution_config = env.get_config() 以下是可用的配置选项：（默认为粗体）
setClosureCleanerLevel()。closure cleaner 的级别默认设置为 ClosureCleanerLevel.RECURSIVE。closure cleaner 删除 Flink 程序中对匿名 function 的调用类的不必要引用。禁用 closure cleaner 后，用户的匿名 function 可能正引用一些不可序列化的调用类。这将导致序列化器出现异常。可设置的值是： NONE：完全禁用 closure cleaner ，TOP_LEVEL：只清理顶级类而不递归到字段中，RECURSIVE：递归清理所有字段。
getParallelism() / setParallelism(int parallelism)。为作业设置默认的并行度。
getMaxParallelism() / setMaxParallelism(int parallelism)。为作业设置默认的最大并行度。此设置决定最大并行度并指定动态缩放的上限。
getNumberOfExecutionRetries() / setNumberOfExecutionRetries(int numberOfExecutionRetries)。设置失败任务重新执行的次数。值为零会有效地禁用容错。-1 表示使用系统默认值（在配置中定义）。该配置已弃用，请改用重启策略 。
getExecutionRetryDelay() / setExecutionRetryDelay(long executionRetryDelay)。设置系统在作业失败后重新执行之前等待的延迟（以毫秒为单位）。在 TaskManagers 上成功停止所有任务后，开始计算延迟，一旦延迟过去，任务会被重新启动。此参数对于延迟重新执行的场景很有用，当尝试重新执行作业时，由于相同的问题，作业会立刻再次失败，该参数便于作业再次失败之前让某些超时相关的故障完全浮出水面（例如尚未完全超时的断开连接）。此参数仅在执行重试次数为一次或多次时有效。该配置已被弃用，请改用重启策略 。</description>
    </item>
    
    <item>
      <title>程序打包</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/datastream/execution/packaging/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/datastream/execution/packaging/</guid>
      <description>程序打包和分布式运行 # 正如之前所描述的，Flink 程序可以使用 remote environment 在集群上执行。或者，程序可以被打包成 JAR 文件（Java Archives）执行。如果使用命令行的方式执行程序，将程序打包是必需的。
打包程序 # 为了能够通过命令行或 web 界面执行打包的 JAR 文件，程序必须使用通过 StreamExecutionEnvironment.getExecutionEnvironment() 获取的 environment。当 JAR 被提交到命令行或 web 界面后，该 environment 会扮演集群环境的角色。如果调用 Flink 程序的方式与上述接口不同，该 environment 会扮演本地环境的角色。
打包程序只要简单地将所有相关的类导出为 JAR 文件，JAR 文件的 manifest 必须指向包含程序入口点（拥有公共 main 方法）的类。实现的最简单方法是将 main-class 写入 manifest 中（比如 main-class: org.apache.flinkexample.MyProgram）。main-class 属性与 Java 虚拟机通过指令 java -jar pathToTheJarFile 执行 JAR 文件时寻找 main 方法的类是相同的。大多数 IDE 提供了在导出 JAR 文件时自动包含该属性的功能。
总结 # 调用打包后程序的完整流程包括两步：
搜索 JAR 文件 manifest 中的 main-class 或 program-class 属性。如果两个属性同时存在，program-class 属性会优先于 main-class 属性。对于 JAR manifest 中两个属性都不存在的情况，命令行和 web 界面支持手动传入入口点类名参数。</description>
    </item>
    
    <item>
      <title>并行执行</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/datastream/execution/parallel/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/datastream/execution/parallel/</guid>
      <description>并行执行 # 本节描述了在 Flink 中配置程序的并行执行。一个 Flink 程序由多个任务 task 组成（转换/算子、数据源和数据接收器）。一个 task 包括多个并行执行的实例，且每一个实例都处理 task 输入数据的一个子集。一个 task 的并行实例数被称为该 task 的 并行度 (parallelism)。
使用 savepoints 时，应该考虑设置最大并行度。当作业从一个 savepoint 恢复时，你可以改变特定算子或着整个程序的并行度，并且此设置会限定整个程序的并行度的上限。由于在 Flink 内部将状态划分为了 key-groups，且性能所限不能无限制地增加 key-groups，因此设定最大并行度是有必要的。
toc 设置并行度 # 一个 task 的并行度可以从多个层次指定：
算子层次 # 单个算子、数据源和数据接收器的并行度可以通过调用 setParallelism()方法来指定。如下所示：
Java final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream&amp;lt;String&amp;gt; text = [...]; DataStream&amp;lt;Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt; wordCounts = text .flatMap(new LineSplitter()) .keyBy(value -&amp;gt; value.f0) .window(TumblingEventTimeWindows.of(Time.seconds(5))) .sum(1).setParallelism(5); wordCounts.print(); env.execute(&amp;#34;Word Count Example&amp;#34;); Scala val env = StreamExecutionEnvironment.getExecutionEnvironment val text = [.</description>
    </item>
    
  </channel>
</rss>

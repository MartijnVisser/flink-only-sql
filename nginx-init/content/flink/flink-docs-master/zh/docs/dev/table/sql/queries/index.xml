<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Queries 查询 on Apache Flink</title>
    <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/</link>
    <description>Recent content in Queries 查询 on Apache Flink</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>概览</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/overview/</guid>
      <description>查询 # SELECT statements and VALUES statements are specified with the sqlQuery() method of the TableEnvironment. The method returns the result of the SELECT statement (or the VALUES statements) as a Table. A Table can be used in subsequent SQL and Table API queries, be converted into a DataStream, or written to a TableSink. SQL and Table API queries can be seamlessly mixed and are holistically optimized and translated into a single program.</description>
    </item>
    
    <item>
      <title>Hints</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/hints/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/hints/</guid>
      <description>Hints # Batch Streaming
SQL hints 是和 SQL 语句一起使用来改变执行计划的。本章介绍如何使用 SQL hints 增强各种方法。
SQL hints 一般可以用于以下：
增强 planner：没有完美的 planner，所以实现 SQL hints 让用户更好地控制执行是非常有意义的； 增加元数据（或者统计信息）：如&amp;quot;已扫描的表索引&amp;quot;和&amp;quot;一些混洗键（shuffle keys）的倾斜信息&amp;quot;的一些统计数据对于查询来说是动态的，用 hints 来配置它们会非常方便，因为我们从 planner 获得的计划元数据通常不那么准确； 算子（Operator）资源约束：在许多情况下，我们会为执行算子提供默认的资源配置，即最小并行度或托管内存（UDF 资源消耗）或特殊资源需求（GPU 或 SSD 磁盘）等，可以使用 SQL hints 非常灵活地为每个查询（非作业）配置资源。 动态表（Dynamic Table）选项 # 动态表选项允许动态地指定或覆盖表选项，不同于用 SQL DDL 或 连接 API 定义的静态表选项，这些选项可以在每个查询的每个表范围内灵活地指定。
因此，它非常适合用于交互式终端中的特定查询，例如，在 SQL-CLI 中，你可以通过添加动态选项/*+ OPTIONS(&#39;csv.ignore-parse-errors&#39;=&#39;true&#39;) */来指定忽略 CSV 源的解析错误。
语法 # 为了不破坏 SQL 兼容性，我们使用 Oracle 风格的 SQL hints 语法：
table_path /*+ OPTIONS(key=val [, key=val]*) */ key: stringLiteral val: stringLiteral 示例 # CREATE TABLE kafka_table1 (id BIGINT, name STRING, age INT) WITH (.</description>
    </item>
    
    <item>
      <title>WITH 子句</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/with/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/with/</guid>
      <description>WITH 子句 # Batch Streaming
WITH 子句提供了一种用于更大查询而编写辅助语句的方法。这些编写的语句通常被称为公用表表达式，表达式可以理解为仅针对某个查询而存在的临时视图。
WITH 子句的语法
WITH &amp;lt;with_item_definition&amp;gt; [ , ... ] SELECT ... FROM ...; &amp;lt;with_item_defintion&amp;gt;: with_item_name (column_name[, ...n]) AS ( &amp;lt;select_query&amp;gt; ) 下面的示例中定义了一个公用表表达式 orders_with_total ，并在一个 GROUP BY 查询中使用它。
WITH orders_with_total AS ( SELECT order_id, price + tax AS total FROM Orders ) SELECT order_id, SUM(total) FROM orders_with_total GROUP BY order_id; Back to top</description>
    </item>
    
    <item>
      <title>SELECT 与 WHERE</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/select/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/select/</guid>
      <description>SELECT 与 WHERE 子句 # Batch Streaming
SELECT 语句的常见语法格式如下所示：
SELECT select_list FROM table_expression [ WHERE boolean_expression ] 这里的 table_expression 可以是任意的数据源。它可以是一张已经存在的表、视图或者 VALUES 子句，也可以是多个现有表的关联结果、或一个子查询。这里我们假设 Orders 表在 Catalog 中处于可用状态，那么下面的语句会从 Orders 表中读出所有的行。
SELECT * FROM Orders 在 select_list 处的 * 表示查询操作将会解析所有列。但是，我们不鼓励在生产中使用 *，因为它会使查询操作在应对 Catalog 变化的时候鲁棒性降低。相反，可以在 select_list 处指定可用列的子集，或者使用声明的列进行计算。例如，假设 Orders 表中有名为 order_id、price 和 tax 的列，那么你可以编写如下查询：
SELECT order_id, price + tax FROM Orders 查询操作还可以在 VALUES 子句中使用内联数据。每一个元组对应一行，另外可以通过设置别名来为每一列指定名称。
SELECT order_id, price FROM (VALUES (1, 2.0), (2, 3.1)) AS t (order_id, price) 可以根据 WHERE 子句对行数据进行过滤。</description>
    </item>
    
    <item>
      <title>SELECT DISTINCT</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/select-distinct/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/select-distinct/</guid>
      <description>SELECT DISTINCT # Batch Streaming
如果使用”SELECT DISTINCT“查询,所有的复制行都会从结果集(每个分组只会保留一行)中被删除.
SELECT DISTINCT id FROM Orders 对于流式查询, 计算查询结果所需要的状态可能会源源不断地增长,而状态大小又依赖不同行的数量.此时,可以通过配置文件为状态设置合适的存活时间(TTL),以防止过大的状态可能对查询结果的正确性的影响.具体配置可参考:查询相关的配置.
Back to top</description>
    </item>
    
    <item>
      <title>窗口函数</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/window-tvf/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/window-tvf/</guid>
      <description>Windowing table-valued functions (Windowing TVFs) # Batch Streaming
Windows are at the heart of processing infinite streams. Windows split the stream into “buckets” of finite size, over which we can apply computations. This document focuses on how windowing is performed in Flink SQL and how the programmer can benefit to the maximum from its offered functionality.
Apache Flink provides several window table-valued functions (TVF) to divide the elements of your table into windows, including:</description>
    </item>
    
    <item>
      <title>窗口聚合</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/window-agg/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/window-agg/</guid>
      <description>Window Aggregation # Window TVF Aggregation # Batch Streaming
Window aggregations are defined in the GROUP BY clause contains &amp;ldquo;window_start&amp;rdquo; and &amp;ldquo;window_end&amp;rdquo; columns of the relation applied Windowing TVF. Just like queries with regular GROUP BY clauses, queries with a group by window aggregation will compute a single result row per group.
SELECT ... FROM &amp;lt;windowed_table&amp;gt; -- relation applied windowing TVF GROUP BY window_start, window_end, ... Unlike other aggregations on continuous tables, window aggregation do not emit intermediate results but only a final result, the total aggregation at the end of the window.</description>
    </item>
    
    <item>
      <title>分组聚合</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/group-agg/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/group-agg/</guid>
      <description>Group Aggregation # Batch Streaming
Like most data systems, Apache Flink supports aggregate functions; both built-in and user-defined. User-defined functions must be registered in a catalog before use.
An aggregate function computes a single result from multiple input rows. For example, there are aggregates to compute the COUNT, SUM, AVG (average), MAX (maximum) and MIN (minimum) over a set of rows.
SELECT COUNT(*) FROM Orders For streaming queries, it is important to understand that Flink runs continuous queries that never terminate.</description>
    </item>
    
    <item>
      <title>Over聚合</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/over-agg/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/over-agg/</guid>
      <description>Over Aggregation # Batch Streaming
OVER aggregates compute an aggregated value for every input row over a range of ordered rows. In contrast to GROUP BY aggregates, OVER aggregates do not reduce the number of result rows to a single row for every group. Instead OVER aggregates produce an aggregated value for every input row.
The following query computes for every order the sum of amounts of all orders for the same product that were received within one hour before the current order.</description>
    </item>
    
    <item>
      <title>Join</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/joins/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/joins/</guid>
      <description>Joins # Batch Streaming
Flink SQL supports complex and flexible join operations over dynamic tables. There are several different types of joins to account for the wide variety of semantics queries may require.
By default, the order of joins is not optimized. Tables are joined in the order in which they are specified in the FROM clause. You can tweak the performance of your join queries, by listing the tables with the lowest update frequency first and the tables with the highest update frequency last.</description>
    </item>
    
    <item>
      <title>窗口关联</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/window-join/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/window-join/</guid>
      <description>Window Join # Batch Streaming
A window join adds the dimension of time into the join criteria themselves. In doing so, the window join joins the elements of two streams that share a common key and are in the same window. The semantic of window join is same to the DataStream window join
For streaming queries, unlike other joins on continuous tables, window join does not emit intermediate results but only emits final results at the end of the window.</description>
    </item>
    
    <item>
      <title>集合操作</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/set-ops/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/set-ops/</guid>
      <description>Set Operations # Batch Streaming
UNION # UNION and UNION ALL return the rows that are found in either table. UNION takes only distinct rows while UNION ALL does not remove duplicates from the result rows.
Flink SQL&amp;gt; create view t1(s) as values (&amp;#39;c&amp;#39;), (&amp;#39;a&amp;#39;), (&amp;#39;b&amp;#39;), (&amp;#39;b&amp;#39;), (&amp;#39;c&amp;#39;); Flink SQL&amp;gt; create view t2(s) as values (&amp;#39;d&amp;#39;), (&amp;#39;e&amp;#39;), (&amp;#39;a&amp;#39;), (&amp;#39;b&amp;#39;), (&amp;#39;b&amp;#39;); Flink SQL&amp;gt; (SELECT s FROM t1) UNION (SELECT s FROM t2); +---+ | s| +---+ | c| | a| | b| | d| | e| +---+ Flink SQL&amp;gt; (SELECT s FROM t1) UNION ALL (SELECT s FROM t2); +---+ | c| +---+ | c| | a| | b| | b| | c| | d| | e| | a| | b| | b| +---+ INTERSECT # INTERSECT and INTERSECT ALL return the rows that are found in both tables.</description>
    </item>
    
    <item>
      <title>ORDER BY 语句</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/orderby/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/orderby/</guid>
      <description>ORDER BY 语句 # Batch Streaming
ORDER BY 子句使结果行根据指定的表达式进行排序。 如果两行根据最左边的表达式相等，则根据下一个表达式进行比较，依此类推。 如果根据所有指定的表达式它们相等，则它们以与实现相关的顺序返回。
在流模式下运行时，表的主要排序顺序必须按时间属性升序。 所有后续的 orders 都可以自由选择。 但是批处理模式没有这个限制。
SELECT * FROM Orders ORDER BY order_time, order_id Back to top</description>
    </item>
    
    <item>
      <title>LIMIT 语句</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/limit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/limit/</guid>
      <description>LIMIT 语句 # Batch LIMIT 子句限制 SELECT 语句返回的行数。 通常，此子句与 ORDER BY 结合使用，以确保结果是确定性的。
以下示例选择 Orders 表中的前 3 行。
SELECT * FROM Orders ORDER BY orderTime LIMIT 3 Back to top</description>
    </item>
    
    <item>
      <title>Top-N</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/topn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/topn/</guid>
      <description>Top-N # Batch Streaming
Top-N queries ask for the N smallest or largest values ordered by columns. Both smallest and largest values sets are considered Top-N queries. Top-N queries are useful in cases where the need is to display only the N bottom-most or the N top- most records from batch/streaming table on a condition. This result set can be used for further analysis.
Flink uses the combination of a OVER window clause and a filter condition to express a Top-N query.</description>
    </item>
    
    <item>
      <title>窗口 Top-N</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/window-topn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/window-topn/</guid>
      <description>Window Top-N # Batch Streaming
Window Top-N is a special Top-N which returns the N smallest or largest values for each window and other partitioned keys.
For streaming queries, unlike regular Top-N on continuous tables, window Top-N does not emit intermediate results but only a final result, the total top N records at the end of the window. Moreover, window Top-N purges all intermediate state when no longer needed. Therefore, window Top-N queries have better performance if users don&amp;rsquo;t need results updated per record.</description>
    </item>
    
    <item>
      <title>窗口去重</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/window-deduplication/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/window-deduplication/</guid>
      <description>Window Deduplication # Streaming Window Deduplication is a special Deduplication which removes rows that duplicate over a set of columns, keeping the first one or the last one for each window and partitioned keys.
For streaming queries, unlike regular Deduplicate on continuous tables, Window Deduplication does not emit intermediate results but only a final result at the end of the window. Moreover, window Deduplication purges all intermediate state when no longer needed.</description>
    </item>
    
    <item>
      <title>去重</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/deduplication/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/deduplication/</guid>
      <description>Deduplication # Batch Streaming
Deduplication removes rows that duplicate over a set of columns, keeping only the first one or the last one. In some cases, the upstream ETL jobs are not end-to-end exactly-once; this may result in duplicate records in the sink in case of failover. However, the duplicate records will affect the correctness of downstream analytical jobs - e.g. SUM, COUNT - so deduplication is needed before further analysis.</description>
    </item>
    
    <item>
      <title>模式检测</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/match_recognize/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/dev/table/sql/queries/match_recognize/</guid>
      <description>模式检测 # Streaming 搜索一组事件模式（event pattern）是一种常见的用例，尤其是在数据流情景中。Flink 提供复杂事件处理（CEP）库，该库允许在事件流中进行模式检测。此外，Flink 的 SQL API 提供了一种关系式的查询表达方式，其中包含大量内置函数和基于规则的优化，可以开箱即用。
2016 年 12 月，国际标准化组织（ISO）发布了新版本的 SQL 标准，其中包括在 SQL 中的行模式识别（Row Pattern Recognition in SQL）(ISO/IEC TR 19075-5:2016)。它允许 Flink 使用 MATCH_RECOGNIZE 子句融合 CEP 和 SQL API，以便在 SQL 中进行复杂事件处理。
MATCH_RECOGNIZE 子句启用以下任务：
使用 PARTITION BY 和 ORDER BY 子句对数据进行逻辑分区和排序。 使用 PATTERN 子句定义要查找的行模式。这些模式使用类似于正则表达式的语法。 在 DEFINE 子句中指定行模式变量的逻辑组合。 measures 是指在 MEASURES 子句中定义的表达式，这些表达式可用于 SQL 查询中的其他部分。 下面的示例演示了基本模式识别的语法：
SELECT T.aid, T.bid, T.cid FROM MyTable MATCH_RECOGNIZE ( PARTITION BY userid ORDER BY proctime MEASURES A.</description>
    </item>
    
  </channel>
</rss>

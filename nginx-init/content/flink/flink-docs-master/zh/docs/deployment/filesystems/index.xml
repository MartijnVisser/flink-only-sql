<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>File Systems on Apache Flink</title>
    <link>//localhost/flink/flink-docs-master/zh/docs/deployment/filesystems/</link>
    <description>Recent content in File Systems on Apache Flink</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="//localhost/flink/flink-docs-master/zh/docs/deployment/filesystems/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>通用配置</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/deployment/filesystems/common/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/deployment/filesystems/common/</guid>
      <description>通用配置 # Apache Flink 提供了一些对所有文件系统均适用的基本配置。
默认文件系统 # 如果文件路径未明确指定文件系统的 scheme（和 authority），将会使用默认的 scheme（和 authority）：
fs.default-scheme: &amp;lt;default-fs&amp;gt; 例如默认的文件系统配置为 fs.default-scheme: hdfs://localhost:9000/，则文件路径 /user/hugo/in.txt 将被处理为 hdfs://localhost:9000/user/hugo/in.txt。
连接限制 # 如果文件系统不能处理大量并发读/写操作或连接，可以为文件系统同时打开的总连接数设置上限。
例如在一个大型 Flink 任务建立 checkpoint 时，具有少量 RPC handler 的小型 HDFS 集群可能会由于建立了过多的连接而过载。
要限制文件系统的连接数，可将下列配置添加至 Flink 配置中。设置限制的文件系统由其 scheme 指定：
fs.&amp;lt;scheme&amp;gt;.limit.total: (数量，0/-1 表示无限制) fs.&amp;lt;scheme&amp;gt;.limit.input: (数量，0/-1 表示无限制) fs.&amp;lt;scheme&amp;gt;.limit.output: (数量，0/-1 表示无限制) fs.&amp;lt;scheme&amp;gt;.limit.timeout: (毫秒，0 表示无穷) fs.&amp;lt;scheme&amp;gt;.limit.stream-timeout: (毫秒，0 表示无穷) 输入和输出连接（流）的数量可以分别进行限制（fs.&amp;lt;scheme&amp;gt;.limit.input 和 fs.&amp;lt;scheme&amp;gt;.limit.output），也可以限制并发流的总数（fs.&amp;lt;scheme&amp;gt;.limit.total）。如果文件系统尝试打开更多的流，操作将被阻塞直至某些流关闭。如果打开流的时间超过 fs.&amp;lt;scheme&amp;gt;.limit.timeout，则流打开失败。
为避免不活动的流占满整个连接池（阻止新连接的建立），可以在配置中添加无活动超时时间，如果连接至少在 fs.&amp;lt;scheme&amp;gt;.limit.stream-timeout 时间内没有读/写操作，则连接会被强制关闭。
连接数是按每个 TaskManager/文件系统来进行限制的。因为文件系统的创建是按照 scheme 和 authority 进行的，所以不同的 authority 具有独立的连接池，例如 hdfs://myhdfs:50010/ 和 hdfs://anotherhdfs:4399/ 会有单独的连接池。</description>
    </item>
    
    <item>
      <title>文件系统</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/deployment/filesystems/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/deployment/filesystems/overview/</guid>
      <description>文件系统 # Apache Flink 使用文件系统来消费和持久化地存储数据，以处理应用结果以及容错与恢复。以下是一些最常用的文件系统：本地存储，hadoop-compatible，Amazon S3，阿里云 OSS 和 Azure Blob Storage。
文件使用的文件系统通过其 URI Scheme 指定。例如 file:///home/user/text.txt 表示一个在本地文件系统中的文件，hdfs://namenode:50010/data/user/text.txt 表示一个在指定 HDFS 集群中的文件。
文件系统在每个进程实例化一次，然后进行缓存/池化，从而避免每次创建流时的配置开销，并强制执行特定的约束，如连接/流的限制。
本地文件系统 # Flink 原生支持本地机器上的文件系统，包括任何挂载到本地文件系统的 NFS 或 SAN 驱动器，默认即可使用，无需额外配置。本地文件可通过 file:// URI Scheme 引用。
外部文件系统 # Apache Flink 支持下列文件系统：
Amazon S3 对象存储由 flink-s3-fs-presto 和 flink-s3-fs-hadoop 两种替代实现提供支持。这两种实现都是独立的，没有依赖项。
阿里云对象存储 由 flink-oss-fs-hadoop 支持，并通过 oss:// URI scheme 使用。该实现基于 Hadoop Project，但其是独立的，没有依赖项。
Azure Blob Storage 由flink-azure-fs-hadoop 支持，并通过 abfs(s):// 和 wasb(s):// URI scheme 使用。该实现基于 Hadoop Project，但其是独立的，没有依赖项。
Google Cloud Storage 由gcs-connector 支持，并通过 gs:// URI scheme 使用。该实现基于 Hadoop Project，但其是独立的，没有依赖项。</description>
    </item>
    
    <item>
      <title>Amazon S3</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/deployment/filesystems/s3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/deployment/filesystems/s3/</guid>
      <description>Amazon S3 # Amazon Simple Storage Service (Amazon S3) 提供用于多种场景的云对象存储。S3 可与 Flink 一起使用以读取、写入数据，并可与 流的 State backends 相结合使用。
通过以下格式指定路径，S3 对象可类似于普通文件使用：
s3://&amp;lt;your-bucket&amp;gt;/&amp;lt;endpoint&amp;gt; Endpoint 可以是一个文件或目录，例如：
// 读取 S3 bucket env.readTextFile(&amp;#34;s3://&amp;lt;bucket&amp;gt;/&amp;lt;endpoint&amp;gt;&amp;#34;); // 写入 S3 bucket stream.writeAsText(&amp;#34;s3://&amp;lt;bucket&amp;gt;/&amp;lt;endpoint&amp;gt;&amp;#34;); // 使用 S3 作为 FsStatebackend env.setStateBackend(new FsStateBackend(&amp;#34;s3://&amp;lt;your-bucket&amp;gt;/&amp;lt;endpoint&amp;gt;&amp;#34;)); 注意这些例子并不详尽，S3 同样可以用在其他场景，包括 JobManager 高可用配置 或 RocksDBStateBackend，以及所有 Flink 需要使用文件系统 URI 的位置。
在大部分使用场景下，可使用 flink-s3-fs-hadoop 或 flink-s3-fs-presto 两个独立且易于设置的 S3 文件系统插件。然而在某些情况下，例如使用 S3 作为 YARN 的资源存储目录时，可能需要配置 Hadoop S3 文件系统。
Hadoop/Presto S3 文件系统插件 # 如果您在使用 Flink on EMR，您无需手动对此进行配置。 Flink 提供两种文件系统用来与 S3 交互：flink-s3-fs-presto 和 flink-s3-fs-hadoop。两种实现都是独立的且没有依赖项，因此使用时无需将 Hadoop 添加至 classpath。</description>
    </item>
    
    <item>
      <title>Google Cloud Storage</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/deployment/filesystems/gcs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/deployment/filesystems/gcs/</guid>
      <description>Google Cloud Storage # Google Cloud storage (GCS) provides cloud storage for a variety of use cases. You can use it for reading and writing data, and for checkpoint storage when using FileSystemCheckpointStorage) with the streaming state backends.
You can use GCS objects like regular files by specifying paths in the following format:
gs://&amp;lt;your-bucket&amp;gt;/&amp;lt;endpoint&amp;gt; The endpoint can either be a single file or a directory, for example:
// Read from GSC bucket env.</description>
    </item>
    
    <item>
      <title>阿里云 OSS</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/deployment/filesystems/oss/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/deployment/filesystems/oss/</guid>
      <description>阿里云对象存储服务 (OSS) # OSS：对象存储服务 # 阿里云对象存储服务 (Aliyun OSS) 使用广泛，尤其在中国云用户中十分流行，能提供多种应用场景下的云对象存储。OSS 可与 Flink 一起使用以读取与存储数据，以及与流 State Backend 结合使用。
通过以下格式指定路径，OSS 对象可类似于普通文件使用：
oss://&amp;lt;your-bucket&amp;gt;/&amp;lt;object-name&amp;gt; 以下代码展示了如何在 Flink 作业中使用 OSS：
// 读取 OSS bucket env.readTextFile(&amp;#34;oss://&amp;lt;your-bucket&amp;gt;/&amp;lt;object-name&amp;gt;&amp;#34;); // 写入 OSS bucket stream.writeAsText(&amp;#34;oss://&amp;lt;your-bucket&amp;gt;/&amp;lt;object-name&amp;gt;&amp;#34;); // 将 OSS 用作 FsStatebackend env.setStateBackend(new FsStateBackend(&amp;#34;oss://&amp;lt;your-bucket&amp;gt;/&amp;lt;object-name&amp;gt;&amp;#34;)); Shaded Hadoop OSS 文件系统 # 为使用 flink-oss-fs-hadoop，在启动 Flink 之前，将对应的 JAR 文件从 opt 目录复制到 Flink 发行版中的 plugin 目录下的一个文件夹中，例如：
mkdir ./plugins/oss-fs-hadoop cp ./opt/flink-oss-fs-hadoop-1.16-SNAPSHOT.jar ./plugins/oss-fs-hadoop/ flink-oss-fs-hadoop 为使用 oss:// scheme 的 URI 注册了默认的文件系统包装器。
配置设置 # 在设置好 OSS 文件系统包装器之后，需要添加一些配置以保证 Flink 有权限访问 OSS buckets。</description>
    </item>
    
    <item>
      <title>Azure Blob 存储</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/deployment/filesystems/azure/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/deployment/filesystems/azure/</guid>
      <description>Azure Blob 存储 # Azure Blob 存储 是一项由 Microsoft 管理的服务，能提供多种应用场景下的云存储。 Azure Blob 存储可与 Flink 一起使用以读取和写入数据，以及与流 State Backend 结合使用。
Flink 支持使用 wasb:// 或 abfs:// 访问 Azure Blob 存储。
Azure 建议使用 abfs:// 访问 ADLS Gen2 存储帐户，尽管 wasb:// 通过向后兼容也可以工作。 abfs:// 只能用于访问 ADLS Gen2 存储帐户。 请访问Azure文档，了解如何识别 ADLS Gen2 存储帐户。 通过以下格式指定路径，Azure Blob 存储对象可类似于普通文件使用：
// WASB unencrypted access wasb://&amp;lt;your-container&amp;gt;@$&amp;lt;your-azure-account&amp;gt;.blob.core.windows.net/&amp;lt;object-path&amp;gt; // WASB SSL encrypted access wasbs://&amp;lt;your-container&amp;gt;@$&amp;lt;your-azure-account&amp;gt;.blob.core.windows.net/&amp;lt;object-path&amp;gt; // ABFS unecrypted access abfs://&amp;lt;your-container&amp;gt;@$&amp;lt;your-azure-account&amp;gt;.dfs.core.windows.net/&amp;lt;object-path&amp;gt; // ABFS SSL encrypted access abfss://&amp;lt;your-container&amp;gt;@$&amp;lt;your-azure-account&amp;gt;.</description>
    </item>
    
    <item>
      <title>Plugins</title>
      <link>//localhost/flink/flink-docs-master/zh/docs/deployment/filesystems/plugins/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//localhost/flink/flink-docs-master/zh/docs/deployment/filesystems/plugins/</guid>
      <description>Plugins # Plugins facilitate a strict separation of code through restricted classloaders. Plugins cannot access classes from other plugins or from Flink that have not been specifically whitelisted. This strict isolation allows plugins to contain conflicting versions of the same library without the need to relocate classes or to converge to common versions. Currently, file systems and metric reporters are pluggable but in the future, connectors, formats, and even user code should also be pluggable.</description>
    </item>
    
  </channel>
</rss>
